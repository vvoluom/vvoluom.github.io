I"f<h2 id="abstract">Abstract</h2>
<p>Decision trees are models whose structure allows for tracing an explanation of how the final decision was taken. Neural networks known as ’black box’ model, do not readily and explicitly offer an explanation of how the decision was reached. However since Neural Networks are capable of learning knowledge representation it will be very useful to develop methods that interpret the model’s decisions.
In this project Activation Maximisation will be used to search for prototypical inputs that maximise the model’s response for a quantity of interest. A pair-wise prototype comparison is then carried out under different learning conditions, such as number of classes the model deals with. The study is grounded in the area of object spatial relations recognition in images and will shed light on what models are learning about objects in 2D images which should give insight into how the system can be improved.
The spatial relation problem is one where given a subject and an object the correct spatial preposition is predicted. This problem extends beyond just predicting one correct spatial preposition as there are mulitple possible relationships associated between two objects.</p>

<h1 id="contents">Contents</h1>
<ol>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#Background-and-Literature-Review">Background and Literature Review</a>
    <ol>
      <li><a href="#Preamable">Preamable</a></li>
      <li><a href="#Convolutional-Neural-Networks">Convolutional Neural Networks</a>
        <ol>
          <li><a href="#Image-Components">Image Components</a></li>
          <li><a href="#Convolutional-Layer">Convolutional Layer</a></li>
          <li><a href="#ReLU-Layer">ReLU Layer</a></li>
          <li><a href="#Pooling-Layer">Pooling Layer</a></li>
          <li><a href="#Fully-Connected-Layer">Fully Connected Layer</a></li>
          <li><a href="#Final-Layer">Final Layer</a></li>
          <li><a href="#Dropout-Layer">Dropout Layer</a></li>
          <li><a href="#Single-vs-Multi-Label-Classification">Single vs Multi Label Classification</a></li>
          <li><a href="#Training-and-Terminology">Training and Terminology</a></li>
          <li><a href="#Very-Deep-Convolutional-Networks-For-Large-Scale-Image-Recognition">Very Deep Convolutional Networks For Large-Scale Image Recognition</a></li>
        </ol>
      </li>
      <li><a href="#Visual-Relationship-Detection">Visual Relationship Detection</a>
        <ol>
          <li><a href="#Recognition-Using-Visual-Phrases">Recognition Using Visual Phrases</a></li>
          <li><a href="#Visual-Relationship-Detection-with-Language-Priors">Visual Relationship Detection with Language Priors</a></li>
          <li><a href="#Detecting-Visual-Relationships-with-Deep-Relational-Networks">Detecting Visual Relationships with Deep Relational Networks</a></li>
          <li><a href="#A-Study-on-the-Detection-of-Visual-Relationships">A Study on the Detection of Visual Relationships</a></li>
        </ol>
      </li>
      <li><a href="#Datasets">Datasets</a>
        <ol>
          <li><a href="#SpatialVOC2K:-A-Multilingual-Dataset-of-Images-with-Annotations-and-Features-for-Spatial-Relations-between-Objects">SpatialVOC2K: A Multilingual Dataset of Images with Annotations and Features for Spatial Relations between Objects</a></li>
          <li><a href="#Stanford-VRD">Stanford VRD</a></li>
        </ol>
      </li>
      <li><a href="#A-Review-on-Multi-Label-Learning-Algorithms">A Review on Multi-Label Learning Algorithms</a></li>
      <li><a href="#Activation-Maximization">Activation Maximization</a></li>
    </ol>
  </li>
  <li><a href="#Methodology">Methodology</a>
    <ol>
      <li><a href="#Data-Preparation">Data Preparation</a>
        <ol>
          <li><a href="#Stanford-VRD-Dataset">Stanford VRD Dataset</a></li>
          <li><a href="#SpatialVoc2k-Dataset">SpatialVoc2k Dataset</a></li>
          <li><a href="#Geometric-Datasets">Geometric Datasets</a></li>
          <li><a href="#Single-Label-Datasets">Single Label Datasets</a></li>
        </ol>
      </li>
      <li><a href="#Image-Preparation">Image Preparation</a></li>
      <li><a href="#Training">Training</a>
        <ol>
          <li><a href="#VGG16">VGG16</a></li>
          <li><a href="#Feed-Forward-Neural-Network">Feed Forward Neural Network</a></li>
          <li><a href="#Data-Generators">Data Generators</a></li>
        </ol>
      </li>
      <li><a href="#Evaluation-and-Metrics">Evaluation and Metrics</a></li>
      <li><a href="#Interpreting-the-models">Interpreting the models</a></li>
    </ol>
  </li>
  <li><a href="#Findings">Findings</a>
    <ol>
      <li><a href="#Preamble">Preamble</a></li>
      <li><a href="#VRD-Dataset-Evaluation-Results">VRD Dataset Evaluation Results</a>
        <ol>
          <li><a href="#VGG16-Evaluation-Results">VGG16 Evaluation Results</a></li>
          <li><a href="#Feed-Forward-Evaluation-Results">Feed Forward Evaluation Results</a></li>
          <li><a href="#Activation-Maximization-Evaluation-Results">Activation Maximization Evaluation Results</a></li>
        </ol>
      </li>
      <li><a href="#SpatialVoc2k-Dataset-Evaluation-Results">SpatialVoc2k Dataset Evaluation Results</a>
        <ol>
          <li><a href="#VGG16-Evaluation-Results">VGG16 Evaluation Results</a></li>
          <li><a href="#Feed-Forward-Evaluation-Results">Feed Forward Evaluation Results</a></li>
          <li><a href="#Activation-Maximization-Evaluation-Results">Activation Maximization Evaluation Results</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#Analysis-of-Results">Analysis of Results</a>
    <ol>
      <li><a href="#Preamble">Preamble</a></li>
      <li><a href="#VRD-Results">VRD Results</a>
        <ol>
          <li><a href="#Multi-label-vs-Single-label-Classification">Multi-label vs Single-label Classification</a></li>
          <li><a href="#VGG16-vs-Feed-Forward-Neural-Network">VGG16 vs Feed Forward Neural Network</a></li>
          <li><a href="#Activation-Maximization">Activation Maximization</a></li>
          <li><a href="#Conclusions">Conclusions</a></li>
        </ol>
      </li>
      <li><a href="#SpatialVoc2k-Results">SpatialVoc2k Results</a>
        <ol>
          <li><a href="#Multi-label-vs-Single-label-Classification">Multi-label vs Single-label Classification</a></li>
          <li><a href="#VGG16-vs-Feed-Forward-Neural-Network">VGG16 vs Feed Forward Neural Network</a></li>
          <li><a href="#Activation-Maximization">Activation Maximization</a></li>
          <li><a href="#Conclusions">Conclusions</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#References">References</a></li>
</ol>
:ET